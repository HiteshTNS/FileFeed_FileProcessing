import json
import boto3
import urllib.parse
import os
import logging
from io import BytesIO
import pandas as pd
from botocore.config import Config
import uuid

logger = logging.getLogger()
logger.setLevel(logging.INFO)

s3 = boto3.client('s3')
bedrock_agent_runtime = boto3.client(
    'bedrock-agent-runtime',
    region_name="us-west-2",
    config=Config(connect_timeout=10, read_timeout=120)
)

AGENT_ID = "QDTSICEWAF"
AGENT_ALIAS_ID = "VKDENPWHZV"
HARD_CODED_TEMPLATE = "A8"

AGENT_FILENAME_VALIDATION_PROMPT = (
    "You will receive a file name and a template name. "
    "Your task is to validate whether the file name exists for the given template "
    "in the 'Agent File Specification' sheet under the 'File Name' column. "
    "If the file name matches for the template, return JSON: "
    '{"Validation": "Success", "InputFileName": "<the incoming file name>", "SpecifcationFileName": "<the file name from Agent File Specification>"} '
    "If not, return JSON: "
    '{"Validation": "Failed", "InputFileName": "<the incoming file name>", "SpecifcationFileName": "<the file name from Agent File Specification>"} '
    "Do not return any extra text or explanation."
)

# Updated mapping prompt, explicitly instructing not to hallucinate or skip vehicleType (V0 : Working)
# AGENT_HEADER_MAPPING_PROMPT = (
#     "Instructions: For each header in Output Field Specification (column 'Field Name', in exact order), attempt to map to one of the input headers using the following logic:\n"
#     "When reading alias cells, treat comma-separated values as distinct aliases. Always preserve the original inputHeader exactly as received in the file, even if it matches one of the aliases.\n"
#     "For each input header, find all alias lists for standardized headers under template column \"A8\" in \"Agent File Input Headers\".\n"
#     "Check if input header exactly or fuzzily matches an alias for a standardized header.\n"
#     "Confirm the standardized header exists in Output Field Specification under 'Field Name'.\n"
#     "If found, map input header to this standardized header with confidenceScore 100 for exact, 80 for fuzzy.\n"
#     "If no standardized header found via aliases, but input header is in 'Input headers with data', self-map it with confidenceScore 0.\n"
#     "After mapping all standardized headers, add any unmapped standardized headers as placeholders with inputHeader = mappedHeader and confidenceScore 0.\n"
#     "Append any remaining unmapped input headers with data at the end.\n"
#     "Do not produce duplicate mappedHeader values in output.\n"
#     "Output a JSON array ordered exactly as Output Field Specification 'Field Name' list, followed by any extra input headers.\n"
#     "Respond ONLY with the JSON array, no explanations or extra text."
# )

#(V1: Working with one issue)(working 100%)
# AGENT_HEADER_MAPPING_PROMPT = (
#     "Instructions: For each header in Output Field Specification (column 'Field Name', in exact order), attempt to map to one of the input headers using the following logic:\n"
#     "When reading alias cells, treat comma-separated values as distinct aliases. Always preserve the original inputHeader exactly as received in the file, even if it matches one of the aliases.\n"
#     "For each input header, find all alias lists for standardized headers under template column \"A8\" in \"Agent File Input Headers\".\n"
#     "Check if input header exactly or fuzzily matches an alias for a standardized header.\n"
#     "Confirm the standardized header exists in Output Field Specification under 'Field Name'.\n"
#     "If found, map input header to this standardized header with confidenceScore 100 for exact, 80 for fuzzy.\n"
#     "If no standardized header found via aliases, but input header is in 'Headers with data', then keep the mappedHeader as empty and fill inputHeader as same as inputHeader with conficence score 0.\n"
#     "After mapping all standardized headers, add any unmapped standardized headers as placeholders where inputHeader =""(empty) and mappedHeader=""<Standardized_Header>"" with confidenceScore 0(int).\n"
#     "Append any remaining unmapped input headers with data at the end as inputHeader=""<Incoming_Input_header>"" and mappedHeader=""(empty) with confidence score 0(int).\n"
#     "Do not produce duplicate mappedHeader values in output.\n"
#     "Output a JSON array ordered exactly as Output Field Specification 'Field Name' list, followed by any extra input headers.\n"
#     "Respond ONLY with the JSON array, no explanations or extra text."
# )	
#(V1: Working with one issue)(working 100%)
AGENT_HEADER_MAPPING_PROMPT = (
    f"Instructions: For each header in Output Field Specification (column 'Field Name', in exact order), attempt to map to one of the input headers using the following logic:\n"
    f"When reading alias cells, treat comma-separated values as distinct aliases. Always preserve the original inputHeader exactly as received in the file, even if it matches one of the aliases.\n"
    f"Inside Agent File Input Headers File First row consist the Different File names and second row Consist the different Templates with it's data in column wise. \n"
    f"For each input header, find all alias lists for standardized headers under template column \"{HARD_CODED_TEMPLATE}\" in \"Agent File Input Headers\".\n"
    f"Check if input header exactly or fuzzily matches an alias for a standardized header.\n"
    f"Confirm the standardized header exists in Output Field Specification under 'Field Name'.\n"
    f"If found, map input header to this standardized header with confidenceScore 100 for exact, 80 for fuzzy.\n"
    f"If no standardized header found via aliases, but input header is in 'Headers with data', then keep the mappedHeader as empty and fill inputHeader as same as inputHeader with confidence score 0.\n"
    f"After mapping all standardized headers, add any unmapped standardized headers as placeholders where inputHeader =\"\" (empty) and mappedHeader=\"<Standardized_Header>\" with confidenceScore 0 (int).\n"
    f"Append any remaining unmapped input headers with data at the end as inputHeader=\"<Incoming_Input_header>\" and mappedHeader=\"\" (empty) with confidence score 0 (int).\n"
    f"Do not produce duplicate mappedHeader values in output.\n"
    f"Output a JSON array ordered exactly as Output Field Specification 'Field Name' list, followed by any extra input headers.\n"
    f"Respond ONLY with the JSON array, no explanations or extra text."
)


# AGENT_HEADER_MAPPING_PROMPT = (
#     "Instructions: For each header in Output Field Specification (column 'Field Name', in exact order), attempt to map to one of the input headers using the following logic:\n"
#     "When reading alias cells, treat comma-separated values as distinct aliases. Always preserve the original inputHeader exactly as received in the file, even if it matches one of the aliases.\n"
#     "For each input header, find all alias lists for standardized headers under template column \"A8\" in \"Agent File Input Headers\".\n"
#     "If an input header matches any alias (exact or fuzzy) from that list, always map it to the standardized header (the 'Field Name' value for that row), not to the alias text.\n"
#     "- confidenceScore = 100 if alias exactly equals standardized header name\n"
#     "- confidenceScore = 80 if alias is a close fuzzy match to standardized header name\n"
#     "- confidenceScore = 60 if alias is another listed synonym \n"
#     "Confirm the standardized header exists in Output Field Specification under 'Field Name'.\n"
#     "If found, map input header to this standardized header with confidenceScore 100 for exact, 80 for fuzzy.\n"
#     "If no standardized header found via aliases, but input header is in 'Headers with data', then keep the mappedHeader as empty and fill inputHeader as same as inputHeader with confidence score 0.\n"
#     "After mapping all standardized headers, add any unmapped standardized headers as placeholders where inputHeader is empty (\") and mappedHeader is \"<Standardized_Header>\" with confidenceScore 0 (int).\n"
#     "Append any remaining unmapped input headers with data at the end as inputHeader=\"<Incoming_Input_header>\" and mappedHeader=\"\" (empty) with confidence score 0 (int).\n"
#     "Do not produce duplicate mappedHeader values in output.\n"
#     "Output a JSON array ordered exactly as Output Field Specification 'Field Name' list, followed by any extra input headers.\n"
#     "Respond ONLY with the JSON array, no explanations or extra text."
# )
	

def load_file_once(file_bytes, file_extension):
    try:
        if file_extension == '.csv':
            df = pd.read_csv(BytesIO(file_bytes))
        elif file_extension in ['.xls', '.xlsx']:
            df = pd.read_excel(BytesIO(file_bytes))
        else:
            raise ValueError(f"Unsupported file type: {file_extension}")
        headers = list(df.columns)
        logger.info(f"Extracted headers: {headers}")
        return df, headers
    except Exception as e:
        logger.error(f"Error reading file: {e}")
        raise

def invoke_agent(payload, session_id):
    params = {
        "agentId": AGENT_ID,
        "agentAliasId": AGENT_ALIAS_ID,
        "sessionId": session_id,
        "inputText": payload.strip()
    }
    response = bedrock_agent_runtime.invoke_agent(**params)
    # full_output = ""
    # for event in response.get("completion", []):
    #     if "chunk" in event and "bytes" in event["chunk"]:
    #         full_output += event["chunk"]["bytes"].decode("utf-8")
    # logger.info(f"Raw agent response: {full_output}")
    chunks = []
    for event in response.get("completion", []):
        if "chunk" in event and "bytes" in event["chunk"]:
            chunks.append(event["chunk"]["bytes"].decode("utf-8"))
    full_output = "".join(chunks).strip()
    logger.info(f"Raw agent response: {full_output}")
    return full_output


def create_output_excel(mappings, input_data_df):
    seen = set()
    unique_mappings = []
    # Ensure no duplicate output columns
    for m in mappings:
        # Determine output column name
        col_name = m['mappedHeader'] if m['mappedHeader'] else m['inputHeader']
        if col_name and col_name not in seen:
            m['output_col'] = col_name
            unique_mappings.append(m)
            seen.add(col_name)
    mappings = unique_mappings

    df_out = pd.DataFrame()
    for m in mappings:
        output_col = m['output_col']
        input_header = m['inputHeader']
        # Only create column if output_col is non-empty
        if output_col:
            # If input header is in the input data, use its data; else fill blanks or default
            if input_header in input_data_df.columns:
                col_data = input_data_df[input_header]
                if output_col == "customerCountryCode":
                    col_data = col_data.replace("", pd.NA).fillna("USA")
                elif output_col == "currencyCode":
                    col_data = col_data.replace("", pd.NA).fillna("USD")
                df_out[output_col] = col_data
            else:
                if output_col == "customerCountryCode":
                    df_out[output_col] = "USA"
                elif output_col == "currencyCode":
                    df_out[output_col] = "USD"
                else:
                    df_out[output_col] = ""  # leave blank if not in input

    output_stream = BytesIO()
    df_out.to_excel(output_stream, index=False, engine="openpyxl")
    output_stream.seek(0)
    return output_stream


def lambda_handler(event, context):
    try:
        record = event['Records'][0]
        bucket = record['s3']['bucket']['name']
        key = urllib.parse.unquote_plus(record['s3']['object']['key'])
        file_name = os.path.basename(key)
        template_name = HARD_CODED_TEMPLATE

        logger.info(f"Triggered by file: {key} in bucket: {bucket}")

        validation_payload = f"File Name: {file_name}\nTemplate: {template_name}\n{AGENT_FILENAME_VALIDATION_PROMPT}"
        validation_response = invoke_agent(validation_payload, str(uuid.uuid4()))
        try:
            validation_result = json.loads(validation_response)
        except json.JSONDecodeError:
            logger.error("Invalid JSON from agent in validation step")
            return {'statusCode': 500, 'body': 'Invalid JSON from agent'}

        if validation_result.get("Validation") != "Success":
            logger.error(f"File validation failed for {file_name}.")
            return {'statusCode': 400, 'body': f"File validation failed for {file_name}"}

        _, ext = os.path.splitext(key)
        ext = ext.lower()
        if ext not in ['.csv', '.xls', '.xlsx']:
            return {'statusCode': 400, 'body': f"Unsupported file type {ext}"}

        s3_obj = s3.get_object(Bucket=bucket, Key=key)
        file_bytes = s3_obj['Body'].read()
        input_data_df, headers = load_file_once(file_bytes, ext)
        if not headers:
            return {'statusCode': 400, 'body': 'No headers extracted'}

        headers_csv = ", ".join(headers)
        headers_with_data = [col for col in input_data_df.columns if input_data_df[col].notnull().any() and col.strip()]
        headers_with_data_csv = ", ".join(headers_with_data)
        logger.info(f"Headers with data: {headers_with_data_csv}")

        mapping_payload = (
            f"Template: {template_name}\n"
            f"Input headers: {headers_csv}\n"
            f"Input headers with data: {headers_with_data_csv}\n"
            f"{AGENT_HEADER_MAPPING_PROMPT}"
        )
        logger.info(f"Final mapping payload being sent:\n{mapping_payload}")
        logger.info(f"Sending payload to agent:\n{mapping_payload.encode('unicode_escape').decode()}")
        mapping_response = invoke_agent(mapping_payload, str(uuid.uuid4()))
        try:
            mappings = json.loads(mapping_response)
        except json.JSONDecodeError:
            logger.error("Invalid JSON from agent in mapping step")
            return {'statusCode': 500, 'body': 'Invalid JSON from agent'}

        logger.info(f"Parsed {len(mappings)} mappings")

        output_stream = create_output_excel(mappings, input_data_df)
        base_name = os.path.basename(key)
        name_split = base_name.rsplit('.', 1)
        output_file = f"{name_split[0]}_final.{name_split[1]}" if len(name_split) == 2 else f"{base_name}_final.xlsx"
        output_key = f"output/{output_file}"

        s3.put_object(Bucket=bucket, Key=output_key, Body=output_stream.getvalue())
        logger.info(f"Output saved to {output_key}")

        return {'statusCode': 200, 'body': f"Processed {key}, output saved to {output_key}"}

    except Exception as e:
        logger.error(f"Error processing file: {e}", exc_info=True)
        return {'statusCode': 500, 'body': str(e)}
